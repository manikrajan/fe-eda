{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"County_Analysis_Class.ipynb","provenance":[],"authorship_tag":"ABX9TyOxz7tBLvSwdUkrbmLYP4EI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Bn4hWBm7OKdr"},"outputs":[],"source":["\"\"\"\n","countyAnalysis class used for county level analysis of food environment dataset\n","\n","\"\"\"\n","import pandas as pd\n","import numpy as np\n","import random\n","\n","# Define a class for county level analysis\n","class countyAnalysis:\n","  # Decription of class and fields\n","\n","    def __init__(self, df_county, target_var = None, var_list = None):\n","      '''\n","      Class constructor\n","      df_county: county level dataframe (pre-formatted and cleaned)\n","      target_var: optional, specify variable of interest for future analysis\n","      var_list: optional, specific list of variables you're interested in exploring (i.e. their relation to target)\n","      '''\n","      self.df_county = df_county.copy() # Original dataframe, copy so that changes within class doesn't change original\n","      self.target_var = target_var\n","      self.var_list = var_list\n","    \n","    def select_state(self, state):\n","      # Filter dataframe to counties from a specfific state\n","      self.df_county = self.df_county[self.df_county['State']==state]\n","    \n","    def calculate_na_summary(self):\n","      # Calculate percent missing\n","      self.pct_missing = self.df_county.isnull().sum() * 100 / len(self.df_county)\n","      # Find variable with largest % missing\n","      print('Missing values summary: ')\n","      print('The 10 variables with the highest percent missing are: ') \n","      print(self.pct_missing.nlargest(10))\n","    \n","    def remove_missing_threshold_cols(self, threshold):\n","      print(f\"Removing columns with greater than {(threshold)*100}% missing\")\n","      # Remove variables with more than \"theshold\"% missing\n","      # Threshold in drop na is number of observations so multiply theshold % by number of rows\n","      self.df_county.dropna(thresh=self.df_county.shape[0]*(1-threshold), axis=1, inplace=True)\n","    \n","    def remove_missing_threshold_rows(self, threshold):\n","      print(f\"Removing rows (counties) with greater than {(threshold)*100}% missing\")\n","      # Remove rows (counties) with more than \"theshold\"% missing\n","      # Threshold in drop na is number of observations so multiply theshold % by number of columns\n","      self.df_county.dropna(thresh=self.df_county.shape[1]*(1-threshold), axis=0, inplace=True)\n","    \n","    def calculation_correlations_with_variable(self, num_pos_corr = 10, num_neg_corr = 10, display_all = False):\n","      '''\n","      num_pos_corr: number of top postive correlations to display. Default 10\n","      num_neg_corr: number of top negative correlations to display. Default 10   \n","      display_all: (default false), but if true will display all correlations (not just top pos/neg)\n","      '''\n","      # todo: skip non-numeric columns\n","      # todo: option to remove high correlations\n","      \n","      # If haven't defined variable of interest, prompt user to select\n","      if self.target_var is None:\n","        self.select_target_var()\n","      if self.var_list is not None: # If provided a list of variables only calculte correlations for those\n","        self.corrs_with_var = self.df_county[self.var_list].apply(lambda x: x.corr(self.df_county[self.target_var]))\n","      else: # Otherwise use all other variables (but only numeric columns)\n","        numeric_cols = self.df_county.select_dtypes(include=np.number).columns.tolist() # Select only numeric columns to calculate correlations with target\n","        self.corrs_with_var = self.df_county[numeric_cols].drop([self.target_var],axis=1).apply(lambda x: x.corr(self.df_county[self.target_var]))\n","      if not display_all:\n","        # Display top correlations\n","        print(f'Top {num_pos_corr} largest (positives) correlations with {self.target_var}: ')\n","        print(self.corrs_with_var.nlargest(num_pos_corr))\n","        print(f'Top {num_neg_corr} smallest (negative) correlations {self.target_var}: ')\n","        print(self.corrs_with_var.nsmallest(num_neg_corr))\n","      else:\n","        print(f\"Top correlations with {self.target_var}:\")\n","        print(self.corrs_with_var.sort_values())\n","    \n","    \n","    def find_zero_variance_state_cols(self, drop = False):\n","      # Calculate standard deviation for each variable within each state\n","      # To identify columns that are really at a state level \n","      # (i.e. all counties within the state have the same value)\n","      state_stdev = self.df_county.groupby(['State']).std()\n","    \n","      self.state_zero_var_cols = []\n","      for col in state_stdev.columns:\n","        if state_stdev[col].sum() == 0:\n","          self.state_zero_var_cols.append(col)\n","    \n","      # If desired, drop columns that are really state level\n","      if drop == True:\n","        self.df_county.drop(self.state_zero_var_cols, axis=1, inplace=True)\n","    \n","    \n","    def find_most_recent_data(self, drop = False):\n","      '''\n","      Some of the columns in this dataset measure the same thing but for different years.\n","      For example: 'LACCESS_POP10' and 'LACCESS_POP15'.\n","      For some analysis we may be interested in both of these columns while for others \n","      we may only want to consider the most recent year.\n","      This function helps to find the columns that contain data for multiple years\n","      and gives the option of dropping any that are not the most recent.\n","      '''\n","      column_stub_dict = {}\n","    \n","      # Create dictionary of column name stubs (column name minus last two elements)\n","      # With list of the last two elements (i.e. years) that match each name stub\n","      for i, col in enumerate(self.df_county.columns):\n","        if f'{col[:-2]}' in column_stub_dict: # If we've already searched for columns that match this beginning\n","          continue # Skip this column\n","        column_stub_dict[f'{col[:-2]}'] = [col[-2:]] # Create dictionary row for this beginning\n","        for j, x in enumerate(self.df_county.columns[i+1:]): # Search subsequent columns for match\n","          if col[:-2] == x[:-2]: # If the elements are the same (other than the last two (years))\n","            column_stub_dict[f'{col[:-2]}'].append(x[-2:]) # Add the years to the dictionary\n","    \n","      # Use column name stub dictionary to find latest (and oldest) datapoint for each\n","      self.list_recent_cols = []\n","      self.list_non_recent_cols = []\n","      for stub in column_stub_dict:\n","        if len(column_stub_dict[stub])>1: # if there were more than one column (year) for this stub\n","          int_year_lst = [int(year) for year in column_stub_dict[stub]] # Create list of ints so we can check for max\n","          for year in column_stub_dict[stub]: # Loop through each year\n","            if int(year) == max(int_year_lst): # If it is the max add to list_recent_cols\n","              self.list_recent_cols.append(f'{stub}{year}')\n","            else: # Otherwise add to list of non-recent columns\n","              self.list_non_recent_cols.append(f'{stub}{year}')\n","    \n","      # Keep only the most recent data points (if desired)\n","      if drop == True:\n","        self.df_county.drop(self.list_non_recent_cols, axis=1, inplace=True)\n","    \n","    \n","    def select_variables_to_analyze(self, n):\n","      '''\n","      n: number of variables to select\n","      '''\n","      print(f\"Randomly selecting {n} variables for analysis...\")\n","      all_vars = [var for var in self.df_county.columns if var not in [\"FIPS\",    \"State\",    \"County\"]]\n","      self.var_list = random.sample(all_vars, n)\n","      print(f\"Selected variables: {self.var_list}\")\n","    \n","    def select_target_var(self):\n","        print(\"Please select a variable of interest: \")\n","        self.target_var = input()\n","        if self.target_var not in self.df_county.columns:\n","          print(\"This variable is not in this dataset.\")\n","          print(\"Will be using default (LACCESS_POP15) until a valid variable is chosen.\")\n","          self.target_var = \"LACCESS_POP15\"\n","    \n","    def append_region(self, data_path):\n","        # Read in region data\n","        df_region = pd.read_csv(data_path + 'State and Region.csv')\n","        # Join region data to df_county\n","        self.df_county = pd.merge(self.df_county, df_region, how='inner', on = 'State')\n","    \n","\n","    def average_by_category(self, by_col, new_var_list = None):\n","        '''\n","        Calculate average value of variables by another column\n","        '''\n","        if new_var_list is not None: # If provided a variable list for this function use it\n","            self.average_by = self.df_county.groupby(by_col, as_index=False)[new_var_list].mean()\n","        elif self.var_list is not None: # Otherwise use var_list for the class\n","          self.average_by = self.df_county.groupby(by_col, as_index=False)[self.var_list].mean()\n","        else: # Otherwise calculate for all variables\n","          self.average_by = self.df_county.groupby(by_col, as_index=False).mean()\n","\n","        return self.average_by\n","\n","    def labeled_categorical_cols(self):\n","        # Create column that labels 0/1 in METRO13 variable\n","        self.df_county['Metro'] = np.where(self.df_county['METRO13']==0, \"Non-metro\", \"Metro\")\n","        # Create column that labels 0/1 in PERPOV10 variable\n","        self.df_county['Persistent_Poverty'] = np.where(self.df_county['PERPOV10'] == 1, \"Persistent-Poverty\", \"Other\")"]}]}