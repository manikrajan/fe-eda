{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data_Cleaning_Class.ipynb","provenance":[],"authorship_tag":"ABX9TyPDRqlBnBYjmvEjvjWrpr4z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VfOD2Lt5O_5c"},"outputs":[],"source":["\"\"\"\n","DataCleaning class used for cleaning raw data from the Food Environment Atlas.\n","\"\"\"\n","\n","# Import libraries\n","import pandas as pd\n","import numpy as np\n","import requests\n","from bs4 import BeautifulSoup\n","\n","\n","class DataCleaning:\n","\n","    def __init__(self, df):\n","        '''\n","\t\tInitialize instance of data cleaning class\n","\t\t:param df: dataframe to perform data cleaning on\n","\t\t'''\n","        self.df = df.copy()  # Original dataframe\n","\n","    # copy so that changes within class doesn't change original\n","\n","    def full_data_cleaning(self):\n","        '''\n","\t\t\tMethod to perform all necessary cleaning tasks. Each distinct task/step\n","\t\t\tis defined as its own method and called sequentially.\n","\t\t\t'''\n","        self.clean_state_column()\n","        self.prep_fips_lookup_table()\n","        self.clean_county_column()\n","        self.reformat_data()\n","        self.split_state_county_data()\n","\n","    def clean_state_column(self):\n","        # Fill any nan with empty string\n","        self.df['State'] = self.df['State'].fillna('')\n","        # Remove extra whitespace on some state names\n","        self.df['State'] = self.df['State'].str.strip()\n","\n","    def prep_fips_lookup_table(self):\n","        # Webscrape fips table\n","        self.webscrape_fips_lookup()\n","        # Add missing fips codes to the table\n","        self.add_missing_fips()\n","\n","    def webscrape_fips_lookup(self):\n","        '''\n","\t\tFunction to webscrape fips lookup table\n","\t\t'''\n","        # Define header\n","        headers = {\n","            'user-agent': 'UVA Project (pkx2ec@virginia.edu) (Language=Python 3.8.2; Platform=Macintosh; Intel Mac OS X 11_5_2)'}\n","        # Specify URL\n","        URL = 'https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697'\n","        # Access HTML content\n","        r = requests.get(URL, headers=headers)\n","        # Parse HTML content\n","        soup = BeautifulSoup(r.content, 'html5lib')\n","        # Find data of interest\n","        table = soup.find('div', attrs={'class': 'centerColImg'})\n","        # Create empty dataframe to save FIPS info\n","        self.fips_table = pd.DataFrame(columns=['FIPS', 'County', 'State'])\n","        # Add each FIPS code to dataframe\n","        first_row = True\n","        for row in table.findAll('tr'):\n","            # First row doesn't have the info we want so skip it\n","            if first_row:\n","                first_row = False\n","            else:\n","                row_entries = row.findAll('td')\n","                row_text = [i.text for i in row_entries]\n","                self.fips_table.loc[len(self.fips_table)] = row_text\n","        # Change type of fips table to int so we join it with our data\n","        self.fips_table['FIPS'] = self.fips_table['FIPS'].astype(int)\n","\n","    def add_missing_fips(self):\n","        # Update fips lookup table to add any fips in df, but not fips_table\n","        # List of fips codes in df and fips_table\n","        original_fips = self.df.FIPS.unique()\n","        new_fips = self.fips_table.FIPS.unique()\n","        # For any missing fips, add the info from the first record in df\n","        for i in original_fips:\n","            if i not in new_fips:\n","                self.fips_table.loc[len(self.fips_table.index)] = \\\n","                    self.df.loc[self.df['FIPS'] == i, ['FIPS', 'County', 'State']].iloc[0]\n","\n","    def clean_county_column(self):\n","        # Webscrape fips lookup table\n","        self.prep_fips_lookup_table()\n","        # Add any missing fips codes to the lookup table\n","        self.add_missing_fips()\n","        # Drop original state and county columns (otherwise we'll have 2 columns with the same name)\n","        self.df.drop(['State', 'County'], axis=1, inplace=True)\n","        # Join together fips lookup table\n","        # Left join so we don't lose any data from our original table\n","        self.df = self.df.merge(self.fips_table, on=['FIPS'], how='left')\n","\n","    def reformat_data(self):\n","        # Re-format so variables are across the columns not adding rows in the \"Variable Code\" column\n","        self.pivot = pd.pivot_table(self.df, index=['FIPS', 'State', 'County'], columns='Variable_Code', values='Value')\n","        self.pivot.reset_index(inplace=True)\n","\n","    def split_state_county_data(self):\n","        '''\n","\t\tSome FIPS codes (1-56) are state level, all others are at the county level.\n","\t\tIn addition, some of the variables in the dataset are at the state level\n","\t\t(corresponding to these 1-56 FIPS codes) and thus will be missing for\n","\t\tall the remaining county level FIPS codes. Other variables are at a county\n","\t\tlevel so those will be missing for the state level FIPS codes.\n","\n","\t\tThis method splits the data into a state level and county level dataframe\n","\t\tand removes variables with all missing values in the resulting dataframes.\n","\t\t'''\n","        # Split data based on FIPS code\n","        self.df_state = self.pivot[self.pivot.FIPS <= 56]\n","        self.df_county = self.pivot[self.pivot.FIPS > 56]\n","        # Drop columns with all missing values\n","        self.df_state = self.df_state.dropna(axis=1, how='all')\n","        self.df_county = self.df_county.dropna(axis=1, how='all')"]}]}